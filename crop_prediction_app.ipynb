{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fd7d71b-a8da-4115-b440-c7adf1d11d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    N   P   K  temperature   humidity        ph    rainfall label\n",
      "0  90  42  43    20.879744  82.002744  6.502985  202.935536  rice\n",
      "1  85  58  41    21.770462  80.319644  7.038096  226.655537  rice\n",
      "2  60  55  44    23.004459  82.320763  7.840207  263.964248  rice\n",
      "3  74  35  40    26.491096  80.158363  6.980401  242.864034  rice\n",
      "4  78  42  42    20.130175  81.604873  7.628473  262.717340  rice\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2200 entries, 0 to 2199\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   N            2200 non-null   int64  \n",
      " 1   P            2200 non-null   int64  \n",
      " 2   K            2200 non-null   int64  \n",
      " 3   temperature  2200 non-null   float64\n",
      " 4   humidity     2200 non-null   float64\n",
      " 5   ph           2200 non-null   float64\n",
      " 6   rainfall     2200 non-null   float64\n",
      " 7   label        2200 non-null   object \n",
      "dtypes: float64(4), int64(3), object(1)\n",
      "memory usage: 137.6+ KB\n",
      "None\n",
      "Predicted crop for the new sample: pomegranate\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Crop_recommendation.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "\n",
    "# Preprocess the data\n",
    "# Drop 'label' column and convert to NumPy arrays\n",
    "x = df.drop('label', axis=1).values\n",
    "y = df['label'].values\n",
    "\n",
    "# Encode target labels\n",
    "unique_labels, y_encoded = np.unique(y, return_inverse=True)\n",
    "\n",
    "# Function to compute Euclidean distance\n",
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))\n",
    "\n",
    "# k-NN prediction function\n",
    "def predict(x_train, y_train, x_test, k=3):\n",
    "    predictions = []\n",
    "    for test_point in x_test:\n",
    "        # Calculate distances from the test point to all training points\n",
    "        distances = np.array([euclidean_distance(test_point, train_point) for train_point in x_train])\n",
    "        # Get the indices of the k-nearest neighbors\n",
    "        nearest_indices = np.argsort(distances)[:k]\n",
    "        # Get the labels of the k-nearest neighbors\n",
    "        nearest_labels = y_train[nearest_indices]\n",
    "        # Predict the most common label among the neighbors\n",
    "        unique, counts = np.unique(nearest_labels, return_counts=True)\n",
    "        predicted_label = unique[np.argmax(counts)]\n",
    "        predictions.append(predicted_label)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "def train_test_split(x, y, test_size=0.25, random_state=None):\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    test_set_size = int(x.shape[0] * test_size)\n",
    "    test_indices = indices[:test_set_size]\n",
    "    train_indices = indices[test_set_size:]\n",
    "    \n",
    "    x_train, x_test = x[train_indices], x[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "# Create training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.25, random_state=1)\n",
    "\n",
    "# Predict the crop type for a new sample\n",
    "new_sample = np.array([[14, 5, 36, 24.92639065, 85.192744, 5.802985, 104.735536]])\n",
    "predicted_class_encoded = predict(x_train, y_train, new_sample, k=3)\n",
    "predicted_class = unique_labels[predicted_class_encoded[0]]\n",
    "print(\"Predicted crop for the new sample:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aec69807-2777-46e7-a0b0-b19a2efdf262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to knn_model.pkl\n",
      "Predicted crop for the new sample: pomegranate\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Crop_recommendation.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "x = df.drop('label', axis=1).values\n",
    "y = df['label'].values\n",
    "\n",
    "# Encode target labels\n",
    "unique_labels, y_encoded = np.unique(y, return_inverse=True)\n",
    "\n",
    "class KNNModel:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def euclidean_distance(self, a, b):\n",
    "        return np.sqrt(np.sum((a - b) ** 2))\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        predictions = []\n",
    "        for test_point in x_test:\n",
    "            # Calculate distances from the test point to all training points\n",
    "            distances = np.array([self.euclidean_distance(test_point, train_point) for train_point in self.x_train])\n",
    "            # Get the indices of the k-nearest neighbors\n",
    "            nearest_indices = np.argsort(distances)[:self.k]\n",
    "            # Get the labels of the k-nearest neighbors\n",
    "            nearest_labels = self.y_train[nearest_indices]\n",
    "            # Predict the most common label among the neighbors\n",
    "            unique, counts = np.unique(nearest_labels, return_counts=True)\n",
    "            predicted_label = unique[np.argmax(counts)]\n",
    "            predictions.append(predicted_label)\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "def train_test_split(x, y, test_size=0.25, random_state=None):\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    test_set_size = int(x.shape[0] * test_size)\n",
    "    test_indices = indices[:test_set_size]\n",
    "    train_indices = indices[test_set_size:]\n",
    "    \n",
    "    x_train, x_test = x[train_indices], x[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "# Create training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.25, random_state=1)\n",
    "\n",
    "# Initialize and train the model\n",
    "knn_model = KNNModel(k=3)\n",
    "knn_model.fit(x_train, y_train)\n",
    "\n",
    "# Save the model using pickle\n",
    "pkl_filename = \"knn_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(knn_model, file)\n",
    "\n",
    "print(\"Model saved to\", pkl_filename)\n",
    "\n",
    "# Load the model using pickle\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    loaded_knn_model = pickle.load(file)\n",
    "\n",
    "# Predict using the loaded model\n",
    "new_sample = np.array([[14, 5, 36, 24.92639065, 85.192744, 5.802985, 104.735536]])\n",
    "predicted_class_encoded = loaded_knn_model.predict(new_sample)\n",
    "predicted_class = unique_labels[predicted_class_encoded[0]]\n",
    "print(\"Predicted crop for the new sample:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17d0623e-4692-4a7c-b496-8248eda95f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Crop_recommendation.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "x = df.drop('label', axis=1).values\n",
    "y = df['label'].values\n",
    "\n",
    "# Encode target labels\n",
    "unique_labels, y_encoded = np.unique(y, return_inverse=True)\n",
    "\n",
    "class KNNModel:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def euclidean_distance(self, a, b):\n",
    "        return np.sqrt(np.sum((a - b) ** 2))\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        predictions = []\n",
    "        for test_point in x_test:\n",
    "            distances = np.array([self.euclidean_distance(test_point, train_point) for train_point in self.x_train])\n",
    "            nearest_indices = np.argsort(distances)[:self.k]\n",
    "            nearest_labels = self.y_train[nearest_indices]\n",
    "            unique, counts = np.unique(nearest_labels, return_counts=True)\n",
    "            predicted_label = unique[np.argmax(counts)]\n",
    "            predictions.append(predicted_label)\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "def train_test_split(x, y, test_size=0.25, random_state=None):\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    test_set_size = int(x.shape[0] * test_size)\n",
    "    test_indices = indices[:test_set_size]\n",
    "    train_indices = indices[test_set_size:]\n",
    "    \n",
    "    x_train, x_test = x[train_indices], x[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "# Create training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.25, random_state=1)\n",
    "\n",
    "# Initialize and train the model\n",
    "knn_model = KNNModel(k=3)\n",
    "knn_model.fit(x_train, y_train)\n",
    "\n",
    "# Save the model and unique labels using pickle\n",
    "pkl_filename = \"knn_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump({'model': knn_model, 'labels': unique_labels}, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
